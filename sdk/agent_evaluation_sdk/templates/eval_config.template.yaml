# Evaluation SDK Configuration Template

# Logging Configuration
logging:
  enabled: true
  level: "INFO"
  include_trajectories: true

# Tracing Configuration
tracing:
  enabled: true

# Metrics Configuration
metrics:
  enabled: true

# Dataset Collection Configuration
dataset:
  auto_collect: false  # Set to true when collecting data with --test, then back to false
  storage_location: null  # BigQuery table for storing collected interactions (null = auto-created table)
  buffer_size: 10  # Number of interactions to buffer before writing to BigQuery

# Gen AI Evaluation Configuration
genai_eval:
  metrics: ["bleu", "rouge"]  # Automated metrics
  model_name: "gemini-2.5-flash"  # Model for model-based evaluation
  criteria: ["coherence", "fluency", "safety", "groundedness"]  # Pointwise model-based evaluation criteria
  thresholds:   # Pass Rate Thresholds (0-1 scale) for a test case to be considered "passing"
    bleu: 0.5
    rouge: 0.5
    coherence: 0.7
    fluency: 0.7
    safety: 0.9
    groundedness: 0.7

# Regression Testing Configuration
regression:
  test_limit: null  # Max number of test cases (null = no limit)
  only_reviewed: true  # Only use reviewed test cases
  dataset_table: null  # Read from a custom BigQuery table for test cases (null = use default: {project_id}.agent_evaluation.{agent_name}_eval_dataset)

